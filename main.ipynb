{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "15KTDpG-Cy2JIQo_r4uFYGOYv3cuuySLE",
      "authorship_tag": "ABX9TyPMhq7BPBZcT2r1d/l1v1PX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# YouTube Transcript Generator\n",
        "[![Open in Collab](https://img.shields.io/badge/Open_in_Collab-555?style=for-the-badge&logo=googlecolab&labelColor=gray&color=purple)](https://colab.research.google.com/github/therohitdas/Youtube-Transcript-Generator/blob/main/main.ipynb)\n",
        "![GitHub License](https://img.shields.io/github/license/therohitdas/Youtube-Transcript-Generator?style=for-the-badge&color=blue) ![GitHub Repo stars](https://img.shields.io/github/stars/therohitdas/Youtube-Transcript-Generator?style=for-the-badge&logo=github)\n",
        "\n",
        "## Overview 🌐\n",
        "\n",
        "The YouTube Transcript Generator is a powerful tool designed to streamline the process of extracting and processing transcripts from YouTube videos. Whether you're looking to transcribe lectures, interviews, or any other video content, this project provides a convenient solution.\n",
        "\n",
        "### How It Can Help 🚀\n",
        "\n",
        "This tool is particularly useful for:\n",
        "- **Note Taking:** Quickly convert YouTube videos into text format for easy note-taking.\n",
        "- **Content Analysis:** Analyze and derive insights from video content by converting it into text data.\n",
        "- **Chat Bot Training:** Use the generated transcripts to train chatbots, such as ChatGPT, for natural language understanding.\n",
        "- **Archiving:** Create a textual archive of valuable information from YouTube videos. This can be particularly useful for archiving interviews, tutorials, or any content you'd like to reference later without the need to re-watch the video.\n",
        "- **Personal Knowledge Base:** Build a personal knowledge base by extracting and processing transcripts from YouTube videos. This can aid in consolidating information on diverse topics in a readable and accessible format.\n",
        "- **Accessibility Improvement:** Enhance accessibility for individuals who prefer or require text-based content. The tool can be used to generate transcripts with added punctuation, improving the overall readability of the content.\n",
        "\n",
        "## Features 🛠️\n",
        "\n",
        "- **Transcription:** Obtain raw transcripts from YouTube videos.\n",
        "- **Punctuation:** Enhance transcripts by adding punctuation using [deep multilingual punctuation models](https://huggingface.co/oliverguhr/fullstop-punctuation-multilang-large).\n",
        "- **Chapter Detection:** Identify and separate chapters in the video based on provided timestamps.\n",
        "- **User-friendly:** Easy-to-use script with customizable parameters.\n",
        "\n",
        "## Environment Variables 🌐\n",
        "\n",
        "- `GOOGLE_API_KEY`: Set up your Google API key for video information retrieval. You will need to create a Project in the google cloud for this and enable the YouTube v3 API. This is optional, if you don't add it, the chapters will not be added.\n",
        "\n",
        "## Script Parameters 📜\n",
        "```python\n",
        "url = 'https://www.youtube.com/watch?v=YOUR_VIDEO_ID' # youtu.be link works too\n",
        "language = 'en'\n",
        "punctuated = True # Default False, takes significantly more time when enabled on CPU, use T4 GPU type in google collab.\n",
        "output_dir = '.' # add /content/drive/MyDrive/ to save content in You Google Drive\n",
        "filename = \"\" # Leave empty for default filename: Video Title or Video Id\n",
        "punctuation_model = '' # More info down below\n",
        "verbose = True # To get logs\n",
        "```\n",
        "`language` use the language code to get the video. By default this module always picks manually created transcripts over automatically created ones, if a transcript in the requested language is available both manually created and generated.\n",
        "\n",
        "`punctuation_model` values can be found at https://huggingface.co/oliverguhr/fullstop-punctuation-multilang-large#languages\n",
        "\n",
        "## Support 💬\n",
        "\n",
        "For any issues or feature requests, please [create an issue](https://github.com/therohitdas/Youtube-Transcript-Generator/issues).\n",
        "\n",
        "## Acknowledgments 🙌\n",
        "\n",
        "This script utilizes the [youtube-transcript-api](https://github.com/jdepoix/youtube-transcript-api) and [fullstop-punctuation-multilang-large](https://huggingface.co/oliverguhr/fullstop-punctuation-multilang-large) libraries. Special thanks to their contributors.\n",
        "\n",
        "Feel free to adapt and use the script based on your requirements. Enjoy the convenience of YouTube transcript processing!\n",
        "\n",
        "## Connect with me 📧\n",
        "The best way to connect is to email me [namaste@theRohitDas.com](mailto:namaste@therohitdas.com)\n",
        "- [x/therohitdas](https://x.com/therohitdas)\n",
        "- [GitHub/therohitdas](https://github.com/therohitdas)\n",
        "\n",
        "🚀 Happy transcribing!"
      ],
      "metadata": {
        "id": "UMDjo6KMV590"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-transcript-api deepmultilingualpunctuation nltk tqdm pip install google-api-python-client google-auth-oauthlib"
      ],
      "metadata": {
        "id": "HjaKQBJeT2d7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this if you want to mount and store generated files in google drive.\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "7MBjbAlC8a3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "import re\n",
        "import math\n",
        "import youtube_transcript_api\n",
        "from deepmultilingualpunctuation import PunctuationModel\n",
        "import nltk\n",
        "import warnings\n",
        "import google_auth_oauthlib.flow\n",
        "import googleapiclient.discovery\n",
        "import googleapiclient.errors\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "CCqYukC-T5EN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, force=True)"
      ],
      "metadata": {
        "id": "vPjOXOkseYTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_for_filename(title):\n",
        "    # Define a regular expression to keep only alphanumeric characters, spaces, dots, hyphens, and various parentheses\n",
        "    cleaned_title = re.sub(r'[^\\w\\s\\.\\-\\(\\)\\[\\]]', '', title)\n",
        "\n",
        "    # Remove leading and trailing spaces\n",
        "    return cleaned_title.strip()\n",
        "\n",
        "def remove_music_tags(text):\n",
        "    # Remove [Music] or [music]\n",
        "    updated_text = re.sub(r'\\[music\\]', '', text, flags=re.IGNORECASE)\n",
        "    return updated_text\n",
        "\n",
        "def remove_period_after_hashes(text):\n",
        "    # Remove . after # or ##, considering newline characters\n",
        "    return re.sub(r'(#\\.|##\\.)', lambda match: match.group(1)[:-1], text)\n",
        "\n",
        "def remove_escape_sequences(text):\n",
        "    # Some old videos contain escape sequences like \\n in their subtitle\n",
        "    # Remove \\n, \\r\\n, \\t, \\b, \\r\n",
        "    return re.sub(r'\\\\[nrtb]|\\\\r\\n', '', text)\n",
        "\n",
        "def remove_double_greater_than(text):\n",
        "    # Replace occurrences of \">>\" with an empty string\n",
        "    cleaned_text = re.sub(r'>>', '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "def add_punctuation(text, punctuation_model):\n",
        "    if punctuation_model != \"\":\n",
        "        model = PunctuationModel(model=punctuation_model)\n",
        "    else:\n",
        "        model = PunctuationModel()\n",
        "        punctuated_text = model.restore_punctuation(text)\n",
        "    return punctuated_text\n",
        "\n",
        "def capitalize_sentences(sentences):\n",
        "    # Capitalize the first letter of each sentence in a batch\n",
        "    capitalized_sentences = [sentence[0].upper() + sentence[1:] for sentence in sentences]\n",
        "    return capitalized_sentences\n",
        "\n",
        "def parse_youtube_url(url):\n",
        "    video_id_match = re.search(r'(?:youtube\\.com\\/.*?[?&]v=|youtu\\.be\\/)([^\"&?\\/\\s]{11})', url)\n",
        "    if video_id_match:\n",
        "        return video_id_match.group(1)\n",
        "    else:\n",
        "        raise ValueError('Invalid YouTube URL')\n",
        "\n",
        "def parse_chapters(description):\n",
        "    lines = description.split(\"\\n\")\n",
        "    regex = re.compile(r\"(\\d{0,2}:?\\d{1,2}:\\d{2})\")\n",
        "    chapters = []\n",
        "\n",
        "    for line in lines:\n",
        "        matches = regex.findall(line)\n",
        "        if matches:\n",
        "            ts = matches[0]\n",
        "            title = line.replace(ts, \"\").strip()\n",
        "\n",
        "            # Check if the title contains another timestamp and remove it\n",
        "            title = re.sub(r'\\d{0,2}:?\\d{1,2}:\\d{2}', '', title).strip().strip('-').strip().strip('-').strip()\n",
        "\n",
        "            chapters.append({\n",
        "                \"timestamp\": ts,\n",
        "                \"title\": title,\n",
        "            })\n",
        "\n",
        "    return chapters\n",
        "\n",
        "def get_transcript(video_id, language, video_info, verbose=True):\n",
        "    transcript_list = youtube_transcript_api.YouTubeTranscriptApi.get_transcript(video_id, languages=[language])\n",
        "\n",
        "    if video_info[\"title\"] != \"\":\n",
        "        transcript = f'# {video_info[\"title\"]}\\n\\n'\n",
        "\n",
        "    current_chapter_index = 0\n",
        "    chapters = video_info[\"chapters\"]\n",
        "    logging.info(f\"Transcript_List Length: {len(transcript_list)}, Chapter Length: {len(chapters)}\")\n",
        "\n",
        "    for i, line in enumerate(transcript_list):\n",
        "        start_time = int(math.floor(line['start']))  # Floor and convert to integer\n",
        "\n",
        "        # Check if current_chapter_index is within the valid range\n",
        "        if 0 <= current_chapter_index < len(chapters):\n",
        "            chapter_time = chapters[current_chapter_index]['timestamp']\n",
        "\n",
        "            try:\n",
        "                # Extract start time from the chapter timestamp\n",
        "                chapter_start = chapter_time.strip()\n",
        "                chapter_start_seconds = sum(int(x) * 60 ** i for i, x in enumerate(reversed(chapter_start.split(':'))))\n",
        "                chapters[current_chapter_index][\"title\"] = chapters[current_chapter_index][\"title\"].strip()\n",
        "                buffer_time = 2\n",
        "\n",
        "                if start_time >= chapter_start_seconds - buffer_time:\n",
        "                    logging.info(f'\\n\\n## {chapters[current_chapter_index][\"title\"]}\\n')\n",
        "                    current_chapter_index += 1\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error processing chapter timestamp: {chapter_time}\")\n",
        "                logging.error(f\"Error details: {e}\")\n",
        "\n",
        "        line['text'] = remove_music_tags(line['text'])\n",
        "        line['text'] = remove_escape_sequences(line['text'])\n",
        "        line['text'] = remove_double_greater_than(line['text'])\n",
        "        if line['text']:\n",
        "          transcript += line['text'].strip() + ' '\n",
        "\n",
        "        # Log progress information\n",
        "        if verbose and i % 100 == 0:  # Adjust the log frequency as needed\n",
        "            logging.info(f\"Processed {i} lines out of {len(transcript_list)}\")\n",
        "\n",
        "    return transcript\n",
        "\n",
        "def process_and_save_transcript(video_id, video_info, language, generate_punctuated, output_dir, filename, verbose, punctuation_model):\n",
        "    try:\n",
        "        raw_transcript = get_transcript(video_id, language, video_info, verbose)\n",
        "        logging.info(\"Raw Transcript Length: %d\", len(raw_transcript))\n",
        "\n",
        "        if generate_punctuated:\n",
        "            with_punctuation = add_punctuation(raw_transcript, punctuation_model)\n",
        "            with_punctuation = remove_period_after_hashes(with_punctuation)\n",
        "            logging.info(\"Punctuation Char Length: %d\", len(with_punctuation))\n",
        "            sentences = nltk.sent_tokenize(with_punctuation)\n",
        "            logging.info(\"Sentences to process, (punctuated): %d\", len(sentences))\n",
        "        else:\n",
        "            sentences = nltk.sent_tokenize(raw_transcript)\n",
        "            logging.info(\"Sentences to process, (raw): %d\", len(sentences))\n",
        "\n",
        "        # Capitalize sentences without batching\n",
        "        capitalized_sentences = capitalize_sentences(sentences)\n",
        "\n",
        "        double_linesep = os.linesep + os.linesep\n",
        "        capitalized_transcript = double_linesep.join(capitalized_sentences)\n",
        "        output_path = os.path.join(output_dir, f'{filename}.md')\n",
        "\n",
        "        with open(output_path, 'w', encoding='utf-8') as f:\n",
        "            f.write(capitalized_transcript)\n",
        "\n",
        "        if generate_punctuated:\n",
        "            logging.info(f'Punctuated transcript saved to {output_path}')\n",
        "        else:\n",
        "            logging.info(f'Raw transcript saved to {output_path}')\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f'Error: {e}')\n",
        "\n",
        "def getVideoInfo (video_id):\n",
        "  try:\n",
        "    # Set up Google API credentials using API key\n",
        "    api_key =  userdata.get('GOOGLE_API_KEY') # Replace with your actual API key\n",
        "    youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n",
        "    request = youtube.videos().list(part=\"id,snippet\",\n",
        "                                id = video_id\n",
        "        )\n",
        "    response = request.execute()\n",
        "    title = response['items'][0]['snippet']['title']\n",
        "    description = response['items'][0]['snippet']['description']\n",
        "    data = {\"title\" : title, \"chapters\" : parse_chapters(description)}\n",
        "    return data\n",
        "  except Exception as e:\n",
        "    logging.error(f'Error: {e}')\n",
        "    return {\"title\": \"\", \"chapters\": []}"
      ],
      "metadata": {
        "id": "oasPyMVQoi7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Usage:\n",
        "```python\n",
        "url = 'https://www.youtube.com/watch?v=YOUR_VIDEO_ID' # youtu.be link works too\n",
        "language = 'en'\n",
        "punctuated = True # Default False, takes significantly more time when enabled on CPU, use T4 GPU type in google collab.\n",
        "output_dir = '.' # add /content/drive/MyDrive/ to save content in You Google Drive\n",
        "filename = \"\" # Leave empty for default filename: Video Title or Video Id\n",
        "punctuation_model = '' # More info down below\n",
        "verbose = True # To get logs\n",
        "```\n",
        "`language` use the language code to get the video. By default this module always picks manually created transcripts over automatically created ones, if a transcript in the requested language is available both manually created and generated.\n",
        "\n",
        "`punctuation_model` values can be found at https://huggingface.co/oliverguhr/fullstop-punctuation-multilang-large#languages"
      ],
      "metadata": {
        "id": "U5fmwoG6UFDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.youtube.com/watch?v=CBYhVcO4WgI'\n",
        "language = 'en'\n",
        "punctuated = True # Default False, takes significantly more time when enabled on CPU, use T4 GPU type in google collab.\n",
        "output_dir = '.' # add /content/drive/MyDrive/ to save content in You Google Drive\n",
        "filename = \"\" # Leave empty for default filename: Video Title or Video Id\n",
        "punctuation_model = ''\n",
        "verbose = True"
      ],
      "metadata": {
        "id": "5CT6UxWtUYOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_id = parse_youtube_url(url)\n",
        "video_info = getVideoInfo(video_id)\n",
        "filename = filename = filename or clean_for_filename(video_info[\"title\"]) or clean_for_filename(video_id)"
      ],
      "metadata": {
        "id": "c-M0h6sCmHK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_and_save_transcript(video_id, video_info, language, punctuated, output_dir, filename, verbose, punctuation_model)"
      ],
      "metadata": {
        "id": "CJgLX_DhcPsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the Generated File\n",
        "from google.colab import files\n",
        "files.download(os.path.join(output_dir, f'{filename}.md'))"
      ],
      "metadata": {
        "id": "w9xpxQPTmalR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}