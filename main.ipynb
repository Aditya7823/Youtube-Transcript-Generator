{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxaKaW04bUlr4DGWB33xZ5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/therohitdas/Youtube-Transcript-Generator/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YouTube Transcript Extraction and Processing\n",
        "\n",
        "## Overview\n",
        "\n",
        "This script facilitates the extraction and processing of transcripts from YouTube videos. It leverages the [youtube-transcript-api](https://github.com/jdepoix/youtube-transcript-api) to obtain the raw transcript, allowing users to choose between auto-generated and user-added subtitles. For detailed features and options, refer to the [documentation](https://github.com/jdepoix/youtube-transcript-api).\n",
        "\n",
        "Once the raw transcript is obtained, the script enhances it by adding punctuations using [oliverguhr/fullstop-punctuation-multilang-large](https://huggingface.co/oliverguhr/fullstop-punctuation-multilang-large). This versatile project supports multiple languages for punctuation addition. Please note that punctuation addition may take some time, depending on the length of the video.\n",
        "\n",
        "For reference, it took approximately 5 minutes and 17 seconds to generate the raw transcription and add punctuations for a 1 hour and 38-minute-long video.\n",
        "\n",
        "## Requirements\n",
        "\n",
        "- [youtube-transcript-api](https://github.com/jdepoix/youtube-transcript-api)\n",
        "- [deepmultilingualpunctuation](https://huggingface.co/oliverguhr/fullstop-punctuation-multilang-large)\n",
        "- nltk\n",
        "- tqdm\n",
        "\n",
        "## Usage\n",
        "\n",
        "1. Open the [Google Colab notebook](https://colab.research.google.com/).\n",
        "2. Click on **File > Save a copy in Drive** to create your own version.\n",
        "3. Adjust the script parameters as needed.\n",
        "4. Execute the script cell to process the YouTube video transcript.\n",
        "\n",
        "## Script Parameters\n",
        "\n",
        "- `url`: YouTube video URL.\n",
        "- `language`: Language of the transcript (default: en).\n",
        "- `raw`: Generate raw transcript (default: True).\n",
        "- `punctuated`: Generate punctuated transcript.\n",
        "- `output`: Output directory for the transcript.\n",
        "- `filename`: Filename for the transcript file (excluding extension).\n",
        "- `batch_size`: Batch size for parallel processing (default: 0, auto-detect based on CPU cores).\n",
        "- `verbose`: Enable verbose mode for detailed output (default: True).\n",
        "- `punctuation_model`: Text for the punctuation model (default: '').\n",
        "\n",
        "## Examples\n",
        "\n",
        "```python\n",
        "url = 'https://www.youtube.com/watch?v=YOUR_VIDEO_ID'\n",
        "language = 'en'\n",
        "raw = True\n",
        "punctuated = False\n",
        "output_dir = '/content'\n",
        "filename = 'transcript_notes'\n",
        "batch_size = 0\n",
        "verbose = True\n",
        "punctuation_model = ''\n",
        "\n",
        "video_id = parse_youtube_url(url)\n",
        "process_and_save_transcript(video_id, language, punctuated, output_dir, filename, batch_size, verbose, punctuation_model)\n",
        "```\n",
        "\n",
        "## Acknowledgments\n",
        "This script utilizes the [youtube-transcript-api](https://github.com/jdepoix/youtube-transcript-api) and [deepmultilingualpunctuation](https://huggingface.co/oliverguhr/fullstop-punctuation-multilang-large) libraries. Special thanks to their contributors.\n",
        "\n",
        "Feel free to adapt and use the script based on your requirements. Enjoy the convenience of YouTube transcript processing!\n",
        "\n",
        "## Connect with me\n",
        "I am new to the AI world and will love to connect with other people with this interest.\n",
        "- [x/therohitdas](https://x.com/therohitdas)\n",
        "- [github/therohitdas](https://github.com/therohitdas)"
      ],
      "metadata": {
        "id": "UMDjo6KMV590"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-transcript-api deepmultilingualpunctuation nltk tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjaKQBJeT2d7",
        "outputId": "b07c0044-f0e4-4468-9dde-6f0e1cc79be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: youtube-transcript-api in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: deepmultilingualpunctuation in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.31.0)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from deepmultilingualpunctuation) (2.1.0+cu118)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from deepmultilingualpunctuation) (4.35.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2023.7.22)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation) (0.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->deepmultilingualpunctuation) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->deepmultilingualpunctuation) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import youtube_transcript_api\n",
        "from deepmultilingualpunctuation import PunctuationModel\n",
        "from nltk import sent_tokenize\n",
        "from multiprocessing import Pool\n",
        "import time\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import math\n",
        "import nltk"
      ],
      "metadata": {
        "id": "CCqYukC-T5EN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')"
      ],
      "metadata": {
        "id": "vPjOXOkseYTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "def get_transcript(video_id, language):\n",
        "    transcript_list = youtube_transcript_api.YouTubeTranscriptApi.get_transcript(video_id, languages=[language])\n",
        "    transcript = ''\n",
        "    for line in transcript_list:\n",
        "        if \"[music]\" not in line['text'].lower():\n",
        "            transcript += line['text'] + ' '\n",
        "    return transcript\n",
        "\n",
        "def add_punctuation(text, punctuation_model):\n",
        "    if punctuation_model != \"\":\n",
        "      model = PunctuationModel(model=punctuation_model)\n",
        "    else:\n",
        "      model = PunctuationModel()\n",
        "    return model.restore_punctuation(text)\n",
        "\n",
        "def capitalize_sentences_batch(sentences):\n",
        "    # Capitalize the first letter of each sentence in a batch\n",
        "    capitalized_sentences = [sentence[0].upper() + sentence[1:] for sentence in sentences]\n",
        "    return capitalized_sentences\n",
        "\n",
        "def process_and_save_transcript(video_id, language, generate_punctuated, output_dir, filename, batch_size, verbose, punctuation_model):\n",
        "    try:\n",
        "        raw_transcript = get_transcript(video_id, language)\n",
        "\n",
        "        if generate_punctuated:\n",
        "            with_punctuation = add_punctuation(raw_transcript, punctuation_model)\n",
        "            sentences = sent_tokenize(with_punctuation)\n",
        "            num_processes = os.cpu_count() or 1  # Get the number of available processes\n",
        "            batch_size = 2**int(math.log2(batch_size)) if batch_size else num_processes  # Restrict batch size to be a power of 2, default to number of cores\n",
        "            with Pool() as pool:\n",
        "                capitalized_sentences = list(tqdm(pool.imap(capitalize_sentences_batch, [sentences[i:i+batch_size] for i in range(0, len(sentences), batch_size)]), total=len(sentences), desc='Processing', disable=not verbose))\n",
        "            capitalized_transcript = ' '.join([sentence for batch in capitalized_sentences for sentence in batch])\n",
        "            output_path = os.path.join(output_dir, f'{filename}_punctuated.txt')\n",
        "            with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(capitalized_transcript)\n",
        "            logging.info(f'Punctuated transcript saved to {output_path}')\n",
        "        else:\n",
        "            sentences = sent_tokenize(raw_transcript)\n",
        "            num_processes = os.cpu_count() or 1  # Get the number of available processes\n",
        "            batch_size = 2**int(math.log2(batch_size)) if batch_size else num_processes  # Restrict batch size to be a power of 2, default to number of cores\n",
        "            with Pool() as pool:\n",
        "                capitalized_sentences = list(tqdm(pool.imap(capitalize_sentences_batch, [sentences[i:i+batch_size] for i in range(0, len(sentences), batch_size)]), total=len(sentences), desc='Processing', disable=not verbose))\n",
        "            capitalized_transcript = ' '.join([sentence for batch in capitalized_sentences for sentence in batch])\n",
        "            output_path = os.path.join(output_dir, f'{filename}_raw.txt')\n",
        "            with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(capitalized_transcript)\n",
        "            logging.info(f'Raw transcript saved to {output_path}')\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f'Error: {e}')\n",
        "\n",
        "def parse_youtube_url(url):\n",
        "    video_id_match = re.search(r'(?:youtube\\.com\\/.*?[?&]v=|youtu\\.be\\/)([^\"&?\\/\\s]{11})', url)\n",
        "    if video_id_match:\n",
        "        return video_id_match.group(1)\n",
        "    else:\n",
        "        raise ValueError('Invalid YouTube URL')"
      ],
      "metadata": {
        "id": "oasPyMVQoi7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Usage:\n",
        "```python\n",
        "url = 'https://www.youtube.com/watch?v=YOUR_VIDEO_ID'\n",
        "video_id = parse_youtube_url(url)\n",
        "language = 'en'\n",
        "punctuated = True\n",
        "output_dir = '.'\n",
        "filename = 'output' # Or set it to video_id\n",
        "batch_size = 0\n",
        "verbose = True\n",
        "punctuation_model = ''\n",
        "```\n",
        "`language` use the language code to get the video. By default this module always picks manually created transcripts over automatically created ones, if a transcript in the requested language is available both manually created and generated.\n",
        "\n",
        "`punctuation_model` values can be found at https://huggingface.co/oliverguhr/fullstop-punctuation-multilang-large#languages"
      ],
      "metadata": {
        "id": "U5fmwoG6UFDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.youtube.com/watch?v=4Ff2ZrhVkp0'\n",
        "video_id = parse_youtube_url(url)\n",
        "language = 'en'\n",
        "punctuated = True\n",
        "output_dir = '.'\n",
        "filename = 'new'\n",
        "batch_size = 0\n",
        "verbose = True\n",
        "punctuation_model = ''"
      ],
      "metadata": {
        "id": "5CT6UxWtUYOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_and_save_transcript(video_id, language, punctuated, output_dir, filename, batch_size, verbose, punctuation_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJgLX_DhcPsS",
        "outputId": "036e5df9-0f2d-4af2-8f79-912056d38222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/token_classification.py:169: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"none\"` instead.\n",
            "  warnings.warn(\n",
            "Processing:  51%|█████     | 22/43 [00:00<00:00, 62729.22it/s]\n"
          ]
        }
      ]
    }
  ]
}