{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "15KTDpG-Cy2JIQo_r4uFYGOYv3cuuySLE",
      "authorship_tag": "ABX9TyN3B1MpatCHy0KUWjLgmwh0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/therohitdas/Youtube-Transcript-Generator/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YouTube Transcript Extraction and Processing\n",
        "\n",
        "## Overview\n",
        "\n",
        "This script facilitates the extraction and processing of transcripts from YouTube videos. It leverages the [youtube-transcript-api](https://github.com/jdepoix/youtube-transcript-api) to obtain the raw transcript, allowing users to choose between auto-generated and user-added subtitles. For detailed features and options, refer to the [documentation](https://github.com/jdepoix/youtube-transcript-api).\n",
        "\n",
        "Once the raw transcript is obtained, the script enhances it by adding punctuations using [oliverguhr/fullstop-punctuation-multilang-large](https://huggingface.co/oliverguhr/fullstop-punctuation-multilang-large). This versatile project supports multiple languages for punctuation addition. Please note that punctuation addition may take some time, depending on the length of the video.\n",
        "\n",
        "For reference, it took approximately 5 minutes and 17 seconds to generate the raw transcription and add punctuations for a 1 hour and 38-minute-long video.\n",
        "\n",
        "## Requirements\n",
        "\n",
        "- [youtube-transcript-api](https://github.com/jdepoix/youtube-transcript-api)\n",
        "- [deepmultilingualpunctuation](https://huggingface.co/oliverguhr/fullstop-punctuation-multilang-large)\n",
        "- nltk\n",
        "- tqdm\n",
        "\n",
        "## Usage\n",
        "\n",
        "1. Open the [Google Colab notebook](https://colab.research.google.com/).\n",
        "2. Click on **File > Save a copy in Drive** to create your own version.\n",
        "3. Adjust the script parameters as needed.\n",
        "4. Execute the script cell to process the YouTube video transcript.\n",
        "\n",
        "## Script Parameters\n",
        "\n",
        "- `url`: YouTube video URL.\n",
        "- `language`: Language of the transcript (default: en).\n",
        "- `raw`: Generate raw transcript (default: True).\n",
        "- `punctuated`: Generate punctuated transcript.\n",
        "- `output`: Output directory for the transcript.\n",
        "- `filename`: Filename for the transcript file (excluding extension).\n",
        "- `batch_size`: Batch size for parallel processing (default: 0, auto-detect based on CPU cores).\n",
        "- `verbose`: Enable verbose mode for detailed output (default: True).\n",
        "- `punctuation_model`: Text for the punctuation model (default: '').\n",
        "\n",
        "## Examples\n",
        "\n",
        "```python\n",
        "url = 'https://www.youtube.com/watch?v=YOUR_VIDEO_ID'\n",
        "language = 'en'\n",
        "raw = True\n",
        "punctuated = False\n",
        "output_dir = '/content'\n",
        "filename = 'transcript_notes'\n",
        "batch_size = 0\n",
        "verbose = True\n",
        "punctuation_model = ''\n",
        "\n",
        "video_id = parse_youtube_url(url)\n",
        "process_and_save_transcript(video_id, language, punctuated, output_dir, filename, batch_size, verbose, punctuation_model)\n",
        "```\n",
        "\n",
        "## Acknowledgments\n",
        "This script utilizes the [youtube-transcript-api](https://github.com/jdepoix/youtube-transcript-api) and [deepmultilingualpunctuation](https://huggingface.co/oliverguhr/fullstop-punctuation-multilang-large) libraries. Special thanks to their contributors.\n",
        "\n",
        "Feel free to adapt and use the script based on your requirements. Enjoy the convenience of YouTube transcript processing!\n",
        "\n",
        "## Connect with me\n",
        "I am new to the AI world and will love to connect with other people with this interest.\n",
        "- [x/therohitdas](https://x.com/therohitdas)\n",
        "- [github/therohitdas](https://github.com/therohitdas)"
      ],
      "metadata": {
        "id": "UMDjo6KMV590"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube-transcript-api deepmultilingualpunctuation nltk tqdm pip install google-api-python-client google-auth-oauthlib"
      ],
      "metadata": {
        "id": "HjaKQBJeT2d7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive, userdata\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "7MBjbAlC8a3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import youtube_transcript_api\n",
        "from deepmultilingualpunctuation import PunctuationModel\n",
        "from nltk import sent_tokenize\n",
        "from multiprocessing import Pool\n",
        "import time\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import math\n",
        "import nltk\n",
        "import google_auth_oauthlib.flow\n",
        "import googleapiclient.discovery\n",
        "import googleapiclient.errors"
      ],
      "metadata": {
        "id": "CCqYukC-T5EN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except LookupError:\n",
        "    nltk.download('punkt')\n",
        "logging.basicConfig(level=logging.INFO)"
      ],
      "metadata": {
        "id": "vPjOXOkseYTt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_music_tags(text):\n",
        "    # Remove [Music] or [music]\n",
        "    updated_text = re.sub(r'\\[music\\]', '', text, flags=re.IGNORECASE)\n",
        "    return updated_text\n",
        "\n",
        "def get_transcript(video_id, language, video_info, verbose=True):\n",
        "    transcript_list = youtube_transcript_api.YouTubeTranscriptApi.get_transcript(video_id, languages=[language])\n",
        "    if video_info[\"title\"] != \"\":\n",
        "        transcript = f'# {video_info[\"title\"]}\\n\\n'\n",
        "    current_chapter_index = 0\n",
        "    chapters = video_info[\"chapters\"]\n",
        "\n",
        "    with tqdm(total=len(transcript_list), desc='Processing Transcript', unit='line', disable=not verbose) as pbar:\n",
        "        for line in transcript_list:\n",
        "            start_time = int(math.floor(line['start']))  # Floor and convert to integer\n",
        "\n",
        "            # Check if current_chapter_index is within the valid range\n",
        "            if 0 <= current_chapter_index < len(chapters):\n",
        "                chapter_time = chapters[current_chapter_index]['timestamp']\n",
        "\n",
        "                try:\n",
        "                    # Extract start time from the chapter timestamp\n",
        "                    chapter_start = chapter_time.strip()\n",
        "                    chapter_start_seconds = sum(int(x) * 60 ** i for i, x in enumerate(reversed(chapter_start.split(':'))))\n",
        "                    chapters[current_chapter_index][\"title\"] = chapters[current_chapter_index][\"title\"].strip()\n",
        "                    buffer_time = 2\n",
        "                    if start_time >= chapter_start_seconds - buffer_time:\n",
        "                        transcript += f'\\n\\n## {chapters[current_chapter_index][\"title\"]}\\n'\n",
        "                        current_chapter_index += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing chapter timestamp: {chapter_time}\")\n",
        "                    print(f\"Error details: {e}\")\n",
        "            line['text'] = remove_music_tags(line['text'])\n",
        "            transcript += line['text'].strip() + ' '\n",
        "            pbar.update(1)\n",
        "\n",
        "    return transcript\n",
        "\n",
        "def remove_period_after_hashes(text):\n",
        "    # Remove . after ##, considering newline characters\n",
        "    updated_text = re.sub(r'(?<=##)[.\\n]+', '', text)\n",
        "    return updated_text\n",
        "\n",
        "def add_punctuation(text, punctuation_model):\n",
        "    if punctuation_model != \"\":\n",
        "        model = PunctuationModel(model=punctuation_model)\n",
        "    else:\n",
        "        model = PunctuationModel()\n",
        "        punctuated_text = model.restore_punctuation(text)\n",
        "    return punctuated_text\n",
        "\n",
        "def capitalize_sentences_batch(sentences):\n",
        "    # Capitalize the first letter of each sentence in a batch\n",
        "    capitalized_sentences = [sentence[0].upper() + sentence[1:] for sentence in sentences]\n",
        "    return capitalized_sentences\n",
        "\n",
        "def process_and_save_transcript(video_id, video_info, language, generate_punctuated, output_dir, filename, batch_size, verbose, punctuation_model):\n",
        "    try:\n",
        "        raw_transcript = get_transcript(video_id, language, video_info, verbose)\n",
        "\n",
        "        if generate_punctuated:\n",
        "            with_punctuation = add_punctuation(raw_transcript, punctuation_model)\n",
        "            with_punctuation = remove_period_after_hashes(with_punctuation)\n",
        "            print(with_punctuation)\n",
        "            sentences = sent_tokenize(with_punctuation)\n",
        "            num_processes = os.cpu_count() or 1\n",
        "            batch_size = 2 ** int(math.log2(batch_size)) if batch_size else num_processes\n",
        "\n",
        "            with Pool() as pool:\n",
        "                capitalized_sentences = list(\n",
        "                    tqdm(pool.imap(capitalize_sentences_batch, [sentences[i:i + batch_size] for i in\n",
        "                                                                range(0, len(sentences), batch_size)]),\n",
        "                         total=len(sentences), desc='Processing', disable=not verbose))\n",
        "            capitalized_transcript =  os.linesep.join([sentence for batch in capitalized_sentences for sentence in batch])\n",
        "            output_path = os.path.join(output_dir, f'{filename}.md')\n",
        "            with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(capitalized_transcript)\n",
        "            logging.info(f'Punctuated transcript saved to {output_path}')\n",
        "        else:\n",
        "            sentences = sent_tokenize(raw_transcript)\n",
        "            print (sentences)\n",
        "            num_processes = os.cpu_count() or 1\n",
        "            batch_size = 2 ** int(math.log2(batch_size)) if batch_size else num_processes\n",
        "\n",
        "            with Pool() as pool:\n",
        "                capitalized_sentences = list(\n",
        "                    tqdm(pool.imap(capitalize_sentences_batch, [sentences[i:i + batch_size] for i in\n",
        "                                                                range(0, len(sentences), batch_size)]),\n",
        "                         total=len(sentences), desc='Processing', disable=not verbose))\n",
        "            capitalized_transcript =  os.linesep.join([sentence for batch in capitalized_sentences for sentence in batch])\n",
        "            output_path = os.path.join(output_dir, f'{filename}.md')\n",
        "            with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(capitalized_transcript)\n",
        "            logging.info(f'Raw transcript saved to {output_path}')\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f'Error: {e}')\n",
        "\n",
        "\n",
        "def parse_youtube_url(url):\n",
        "    video_id_match = re.search(r'(?:youtube\\.com\\/.*?[?&]v=|youtu\\.be\\/)([^\"&?\\/\\s]{11})', url)\n",
        "    if video_id_match:\n",
        "        return video_id_match.group(1)\n",
        "    else:\n",
        "        raise ValueError('Invalid YouTube URL')\n",
        "\n",
        "def parse_chapters(description):\n",
        "    lines = description.split(\"\\n\")\n",
        "    regex = re.compile(r\"(\\d{0,2}:?\\d{1,2}:\\d{2})\")\n",
        "    chapters = []\n",
        "\n",
        "    for line in lines:\n",
        "        matches = regex.findall(line)\n",
        "        if matches:\n",
        "            ts = matches[0]\n",
        "            title = line.replace(ts, \"\").strip()\n",
        "\n",
        "            # Check if the title contains another timestamp and remove it\n",
        "            title = re.sub(r'\\d{0,2}:?\\d{1,2}:\\d{2}', '', title).strip().strip('-').strip().strip('-').strip()\n",
        "\n",
        "            chapters.append({\n",
        "                \"timestamp\": ts,\n",
        "                \"title\": title,\n",
        "            })\n",
        "\n",
        "    return chapters\n",
        "\n",
        "def getVideoInfo (video_id):\n",
        "  try:\n",
        "    # Set up Google API credentials using API key\n",
        "    api_key =  userdata.get('GOOGLE_API_KEY') # Replace with your actual API key\n",
        "    youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n",
        "    request = youtube.videos().list(part=\"id,snippet\",\n",
        "                                id = video_id\n",
        "        )\n",
        "    response = request.execute()\n",
        "    title = response['items'][0]['snippet']['title']\n",
        "    description = response['items'][0]['snippet']['description']\n",
        "    data = {\"title\" : title, \"chapters\" : parse_chapters(description)}\n",
        "    return data\n",
        "  except Exception as e:\n",
        "    logging.error(f'Error: {e}')\n",
        "    return {\"title\": \"\", \"chapters\": []}"
      ],
      "metadata": {
        "id": "oasPyMVQoi7u"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Usage:\n",
        "```python\n",
        "url = 'https://www.youtube.com/watch?v=YOUR_VIDEO_ID'\n",
        "video_id = parse_youtube_url(url)\n",
        "language = 'en'\n",
        "punctuated = True\n",
        "output_dir = '.'\n",
        "filename = 'output' # Or set it to video_id\n",
        "batch_size = 0\n",
        "verbose = True\n",
        "punctuation_model = ''\n",
        "```\n",
        "`language` use the language code to get the video. By default this module always picks manually created transcripts over automatically created ones, if a transcript in the requested language is available both manually created and generated.\n",
        "\n",
        "`punctuation_model` values can be found at https://huggingface.co/oliverguhr/fullstop-punctuation-multilang-large#languages"
      ],
      "metadata": {
        "id": "U5fmwoG6UFDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.youtube.com/watch?v=zd_2xpcQuPw'\n",
        "video_id = parse_youtube_url(url)\n",
        "video_info = getVideoInfo(video_id)\n",
        "\n",
        "language = 'en'\n",
        "punctuated = True\n",
        "output_dir = '.'\n",
        "filename = video_info[\"title\"] if video_info[\"title\"] else f'{video_id}_raw'\n",
        "batch_size = 0\n",
        "verbose = False\n",
        "punctuation_model = ''"
      ],
      "metadata": {
        "id": "5CT6UxWtUYOn"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_and_save_transcript(video_id, video_info, language, punctuated, output_dir, filename, batch_size, verbose, punctuation_model)"
      ],
      "metadata": {
        "id": "CJgLX_DhcPsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(os.path.join(output_dir, f'{filename}.md'), \"r\") as f:\n",
        "    content = f.read()\n",
        "    print(content)\n"
      ],
      "metadata": {
        "id": "_rDwVt90A1Py"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}